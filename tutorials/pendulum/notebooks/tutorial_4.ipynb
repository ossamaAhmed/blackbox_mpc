{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Four"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a parallel environment for the pendulum environment and then learn the dynamics model\n",
    "from random rollouts, log the data in tensorboard and use the learned model to control the agent with MPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_neuralmpc.environment_utils import EnvironmentWrapper\n",
    "import logging\n",
    "from tf_neuralmpc.dynamics_functions import DeterministicMLP\n",
    "from tf_neuralmpc.examples.cost_funcs import pendulum_actions_reward_function, pendulum_state_reward_function\n",
    "from tf_neuralmpc import Runner\n",
    "import tensorflow as tf\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_agents = 1\n",
    "log_path = './tutorial_4'\n",
    "single_env, parallel_env = EnvironmentWrapper.make_standard_gym_env(\"Pendulum-v0\", random_seed=0,\n",
    "                                                                    num_of_agents=number_of_agents)\n",
    "my_runner = Runner(env=[single_env, parallel_env],\n",
    "                   log_path=log_path,\n",
    "                   num_of_agents=number_of_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dynamics model architecture now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics_function = DeterministicMLP()\n",
    "state_size = single_env.observation_space.shape[0]\n",
    "input_size = single_env.action_space.shape[0]\n",
    "dynamics_function.add_layer(state_size + input_size,\n",
    "                            32, activation_function=tf.math.tanh)\n",
    "dynamics_function.add_layer(32, 32, activation_function=tf.math.tanh)\n",
    "dynamics_function.add_layer(32, 32, activation_function=tf.math.tanh)\n",
    "dynamics_function.add_layer(32, state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learn the dynamics model using the random rollouts. Note: real number of rollouts in totoal is eqaul to number_of_agents*number_of_rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Started collecting samples for rollouts\n",
      "INFO:root:Average action selection time: 0.0002432107925415039\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00028899312019348145\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00026711463928222654\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024256706237792968\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.0002467143535614014\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00025303959846496583\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.000245743989944458\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.0002495932579040527\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.0002468597888946533\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00025383710861206056\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.0002426326274871826\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.000245208740234375\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024122118949890137\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00023899078369140624\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024109363555908204\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024116873741149902\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024266481399536132\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.000236663818359375\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00023934245109558105\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.0002407848834991455\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00023428201675415039\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024497389793395993\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00022097945213317872\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00022098064422607422\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00022228121757507326\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00022119402885437012\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00023574471473693847\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.0002425503730773926\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.000259169340133667\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00023733615875244141\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.0002360832691192627\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024007678031921388\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024106621742248536\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024090766906738283\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024006128311157226\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024057388305664062\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024295926094055175\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.0002416384220123291\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024036049842834472\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Average action selection time: 0.00024084806442260743\n",
      "INFO:root:Rollout length: 200\n",
      "INFO:root:Finished collecting samples for rollout\n",
      "INFO:root:Started the system training\n",
      "INFO:root:Saving the model now....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ossamaahmed/.virtualenvs/model_based_rl/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ossamaahmed/.virtualenvs/model_based_rl/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./tutorial_4/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./tutorial_4/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "system_dynamics_handler = my_runner.learn_dynamics_from_randomness(number_of_rollouts=40,\n",
    "                                                                   task_horizon=200,\n",
    "                                                                   dynamics_function=dynamics_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-db49ce366194d4df\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-db49ce366194d4df\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6007;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an MPC controller with the learned dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpc_controller = my_runner.make_mpc_policy(system_dynamics_handler=system_dynamics_handler,\n",
    "                                           state_reward_function=pendulum_state_reward_function,\n",
    "                                           actions_reward_function=pendulum_actions_reward_function,\n",
    "                                           planning_horizon=40,\n",
    "                                           optimizer_name='PI2',\n",
    "                                           true_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_runner.record_rollout(horizon=300, policy=mpc_controller,\n",
    "                         record_file_path=log_path+'/episode_1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
